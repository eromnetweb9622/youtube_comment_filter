# ==============================
# OpenAI GPT ëŒ“ê¸€ í•„í„°ë§ ì„œë¹„ìŠ¤ (ê· í˜•ì¡íŒ í•„í„°ë§)
# ==============================

import os
import json
import re
import requests
from dotenv import load_dotenv

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ==============================
# âœ… ì¹´í…Œê³ ë¦¬ ì •ì˜
# ==============================
ALLOWED_CATEGORIES = ["ì •ìƒ", "ìš•ì„¤", "í˜ì˜¤", "ê´‘ê³ ", "ìœ„í—˜"]

# ==============================
# 1ï¸âƒ£ ìš•ì„¤ í•„í„° (ê°•í™”)
# ==============================
BAD_WORD_PATTERNS = [
    r"ì”¨\s*ë°œ", r"ã……\s*ã…‚", r"ë³‘\s*ì‹ ", r"ã…‚\s*ã……",
    r"ì¢†", r"ë¯¸\s*ì¹œ", r"ì§€\s*ë„", r"ê°œ\s*ìƒˆë¼", r"ì—¼ë³‘",
    r"êº¼\s*ì ¸", r"ì£½\s*ì–´"
]

def local_badword_filter(text: str):
    """ëª…í™•í•œ ìš•ì„¤ íŒ¨í„´ ê°ì§€"""
    for pattern in BAD_WORD_PATTERNS:
        if re.search(pattern, text):
            return {"category": "ìš•ì„¤", "reason": "ìš•ì„¤ íŒ¨í„´ ê°ì§€"}
    return None


# ==============================
# 2ï¸âƒ£ ê´‘ê³  í•„í„°
# ==============================
def local_ad_filter(text: str):
    """ëª…í™•í•œ ê´‘ê³  íŒ¨í„´"""
    AD_PATTERNS = [
        r"http[s]?://[^\s]+",  # URL
        r"www\.[^\s]+",
        r"\d{2,4}-\d{3,4}-\d{4}",  # ì „í™”ë²ˆí˜¸
        r"010-?\d{4}-?\d{4}",
        r"ì¹´í†¡\s*ë¬¸ì˜", r"í…”ë ˆê·¸ë¨", r"ì¸ìŠ¤íƒ€\s*@"
    ]
    
    for pattern in AD_PATTERNS:
        if re.search(pattern, text):
            return {"category": "ê´‘ê³ ", "reason": "ê´‘ê³ /í™ë³´ ì˜ì‹¬"}
    return None


# ==============================
# 3ï¸âƒ£ ë¹ ë¥¸ ì •ìƒ í•„í„° (ğŸ”¥ ì‹ ì¤‘í•˜ê²Œ ê°œì„ )
# ==============================
def local_fast_filter(text: str):
    """
    ëª…ë°±íˆ ì•ˆì „í•œ ëŒ“ê¸€ë§Œ í†µê³¼
    âš ï¸ ì• ë§¤í•˜ë©´ GPTë¡œ ë„˜ê¹€
    """
    stripped = text.strip()
    
    # ğŸ”¥ ì•„ì£¼ ì§§ì€ ì´ëª¨í‹°ì½˜ë§Œ ìˆëŠ” ê²½ìš°ë§Œ ì •ìƒ ì²˜ë¦¬
    if len(stripped) <= 3 and not any(char.isalnum() for char in stripped):
        return {"category": "ì •ìƒ", "reason": "ì´ëª¨í‹°ì½˜ ë°˜ì‘"}
    
    # ğŸ”¥ ê¸ì • í‚¤ì›Œë“œ (í•˜ì§€ë§Œ ë¶€ì • í‚¤ì›Œë“œê°€ ì—†ì„ ë•Œë§Œ)
    POSITIVE_WORDS = [
        "ã…‹ã…‹ã…‹", "ã…ã…ã…", "ã… ã… ",  # ìµœì†Œ 3ê¸€ì ì´ìƒ
        "ì¢‹ì•„", "ê·€ì—¬ì›Œ", "ì´ì˜", "ì˜ˆì˜", "ë©‹ìˆ", 
        "ìµœê³ ", "ê°ì‚¬", "ì‘ì›", "ì‚¬ë‘", "ì¶•í•˜",
        "ğŸ‘", "â¤ï¸", "ğŸ’•", "ğŸ˜Š", "ğŸ¥°"
    ]
    
    # ğŸ”¥ ë¶€ì •/ìœ„í—˜ í‚¤ì›Œë“œ (ì´ê²Œ ìˆìœ¼ë©´ GPTë¡œ)
    NEGATIVE_WORDS = [
        "ì£½", "êº¼ì ¸", "ì‹«ì–´", "ìµœì•…", "ì“°ë ˆê¸°",
        "í˜ì˜¤", "ë¬´ì‹", "í•œì‹¬", "ì •ì‹ ", "ë¬¸ì œ"
    ]
    
    has_negative = any(word in stripped for word in NEGATIVE_WORDS)
    
    # ë¶€ì • í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ GPTë¡œ
    if has_negative:
        return None
    
    # ê¸ì • í‚¤ì›Œë“œê°€ ìˆê³  + ë¶€ì •ì´ ì—†ì„ ë•Œë§Œ ì •ìƒ
    has_positive = any(word in stripped for word in POSITIVE_WORDS)
    
    if has_positive and len(stripped) >= 5:  # ìµœì†Œ 5ê¸€ì ì´ìƒ
        return {"category": "ì •ìƒ", "reason": "ê¸ì •ì  ë°˜ì‘"}
    
    return None


# ==============================
# âœ… GPT JSON íŒŒì‹±
# ==============================
def safe_json_parse(content: str):
    match = re.search(r"\[.*\]", content, re.S)
    if not match:
        raise ValueError("JSON ë°°ì—´ ì—†ìŒ")
    return json.loads(match.group())


def chunk_list(data, size=10):
    return [data[i:i + size] for i in range(0, len(data), size)]


# ==============================
# 4ï¸âƒ£ GPT ë°°ì¹˜ ë¶„ì„ (ğŸ”¥ í”„ë¡¬í”„íŠ¸ ê°œì„ )
# ==============================
def analyze_comments_batch(texts: list[str]):
    """
    GPT ë¶„ì„ - ëª…í™•í•œ ê¸°ì¤€ ì œì‹œ
    """
    joined = "\n".join([f"{i+1}. {text}" for i, text in enumerate(texts)])

    payload = {
        "model": "gpt-4o-mini",
        "temperature": 0,
        "messages": [
            {
                "role": "system",
                "content": """ë„ˆëŠ” ìœ íŠœë¸Œ ëŒ“ê¸€ í•„í„°ë§ AIë‹¤.

**ë¶„ë¥˜ ê¸°ì¤€ (ì •í™•í•˜ê²Œ ë”°ë¼ë¼)**

âœ… **ì •ìƒ** - ì´ëŸ° ëŒ“ê¸€ë“¤:
- ì¼ë°˜ì ì¸ ì˜ê²¬, ì§ˆë¬¸
- "ã…‹ã…‹", "ã…ã…", "ã… ã… " ê°™ì€ ê°ì • í‘œí˜„
- ì´ëª¨í‹°ì½˜ ì‚¬ìš© (â¤ï¸, ğŸ˜Š, ğŸ‘)
- "ê·€ì—¬ì›Œ", "ì¢‹ì•„ìš”", "ë©‹ìˆì–´" ê°™ì€ ê¸ì • ë°˜ì‘
- "0:16 ì—¬ê¸° ì¢‹ë‹¤" ê°™ì€ íƒ€ì„ìŠ¤íƒ¬í”„ ëŒ“ê¸€
- ë‹¨ìˆœ ë†ë‹´, ë°ˆ

âš ï¸ **ìš•ì„¤** - ëª…í™•í•œ ìš•ì„¤, ë¹„ì†ì–´

âš ï¸ **í˜ì˜¤** - íŠ¹ì • ì¸ì¢…/ì„±ë³„/ì§‘ë‹¨ì— ëŒ€í•œ ì°¨ë³„ì  ë°œì–¸

âš ï¸ **ê´‘ê³ ** - ìƒí’ˆ í™ë³´, ë§í¬, ì—°ë½ì²˜

ğŸš¨ **ìœ„í—˜** - ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì— í•´ë‹¹:
- íŠ¹ì • ê°œì¸ì— ëŒ€í•œ ì‹¬ê°í•œ ì¸ì‹ ê³µê²©
- í­ë ¥ ì„ ë™, ìœ„í˜‘
- ê°œì¸ì •ë³´ ìœ ì¶œ ì‹œë„
- ìí•´/ìì‚´ ì¡°ì¥

**ì¤‘ìš”**: 
- ë‹¨ìˆœíˆ ë¶€ì •ì  ì˜ê²¬ì€ "ì •ìƒ"ì´ë‹¤
- "ë³„ë¡œë‹¤", "ì¬ë¯¸ì—†ë‹¤" â†’ ì •ìƒ
- ì´ëª¨í‹°ì½˜ë§Œ ìˆìœ¼ë©´ â†’ ì •ìƒ
- ì• ë§¤í•˜ë©´ "ì •ìƒ"ìœ¼ë¡œ ë¶„ë¥˜í•´ë¼

ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ë°˜í™˜í•´ë¼."""
            },
            {
                "role": "user",
                "content": f"""ì•„ë˜ ëŒ“ê¸€ì„ ë¶„ì„í•´.

{joined}

ë°˜í™˜ í˜•ì‹:
[
  {{"index": 1, "category": "ì •ìƒ|ìš•ì„¤|í˜ì˜¤|ê´‘ê³ |ìœ„í—˜", "reason": "í•œ ì¤„ ì„¤ëª…"}}
]"""
            }
        ]
    }

    response = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        },
        json=payload,
        timeout=15
    )

    if response.status_code != 200:
        raise Exception("OpenAI API ì‹¤íŒ¨")

    content = response.json()["choices"][0]["message"]["content"]
    return safe_json_parse(content)


# ==============================
# 5ï¸âƒ£ ë‹¨ì¼ ëŒ“ê¸€ ë¶„ì„
# ==============================
def analyze_comment(text: str):
    """
    ì²˜ë¦¬ ìˆœì„œ:
    1. ìš•ì„¤ í•„í„°
    2. ê´‘ê³  í•„í„°
    3. ì •ìƒ í•„í„° (ì‹ ì¤‘í•˜ê²Œ)
    4. GPT ë¶„ì„
    """
    # 1. ìš•ì„¤ ì²´í¬
    result = local_badword_filter(text)
    if result:
        return result
    
    # 2. ê´‘ê³  ì²´í¬
    result = local_ad_filter(text)
    if result:
        return result
    
    # 3. ì •ìƒ ì²´í¬ (ë§¤ìš° ì‹ ì¤‘)
    result = local_fast_filter(text)
    if result:
        return result

    # 4. GPT ë¶„ì„
    try:
        gpt_result = analyze_comments_batch([text])[0]
        category = gpt_result.get("category", "ìœ„í—˜")
        
        if category not in ALLOWED_CATEGORIES:
            category = "ìœ„í—˜"
        
        return {
            "category": category,
            "reason": gpt_result.get("reason", "AI íŒë‹¨")
        }
    except Exception:
        return {
            "category": "ìœ„í—˜",
            "reason": "AI ë¶„ì„ ì‹¤íŒ¨ (ë³´ìˆ˜ì  ì²˜ë¦¬)"
        }


# ==============================
# 6ï¸âƒ£ ëŒ€ëŸ‰ ëŒ“ê¸€ ë¶„ì„
# ==============================
def analyze_comments_bulk(comments: list[dict]):
    """
    ë¡œì»¬ í•„í„° â†’ GPT ë°°ì¹˜ ì²˜ë¦¬
    """
    results = []
    gpt_targets = []

    # ë¡œì»¬ í•„í„°ë§
    for c in comments:
        text = c["text"]
        
        # ìš•ì„¤ ì²´í¬
        local = local_badword_filter(text)
        if local:
            results.append({**c, **local})
            continue
        
        # ê´‘ê³  ì²´í¬
        local = local_ad_filter(text)
        if local:
            results.append({**c, **local})
            continue
        
        # ì •ìƒ ì²´í¬ (ì‹ ì¤‘í•˜ê²Œ)
        local = local_fast_filter(text)
        if local:
            results.append({**c, **local})
            continue
        
        # GPT ëŒ€ìƒ
        gpt_targets.append(c)

    # GPT ë°°ì¹˜ ë¶„ì„
    batches = chunk_list(gpt_targets, size=10)
    
    for batch in batches:
        texts = [c["text"] for c in batch]
        
        try:
            gpt_results = analyze_comments_batch(texts)
            
            if len(gpt_results) != len(batch):
                raise ValueError("GPT ì‘ë‹µ ê°œìˆ˜ ë¶ˆì¼ì¹˜")
            
            for c, g in zip(batch, gpt_results):
                category = g.get("category", "ìœ„í—˜")
                
                if category not in ALLOWED_CATEGORIES:
                    category = "ìœ„í—˜"
                
                results.append({
                    **c,
                    "category": category,
                    "reason": g.get("reason", "AI íŒë‹¨")
                })
        
        except Exception:
            # ë°°ì¹˜ ì‹¤íŒ¨ ì‹œ ìœ„í—˜ ì²˜ë¦¬
            for c in batch:
                results.append({
                    **c,
                    "category": "ìœ„í—˜",
                    "reason": "AI ë¶„ì„ ì‹¤íŒ¨"
                })

    return results